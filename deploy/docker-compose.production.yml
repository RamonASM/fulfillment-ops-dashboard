version: "3.8"

# =============================================================================
# Inventory Intelligence Platform - Production Docker Compose Configuration
# =============================================================================
# This file defines the complete production stack with all services
# Usage: docker-compose -f deploy/docker-compose.production.yml up -d
# =============================================================================

networks:
  inventory-network:
    driver: bridge

volumes:
  postgres_data:
    driver: local
  redis_data:
    driver: local
  uploads_data:
    driver: local
  ml_models:
    driver: local
  backup_data:
    driver: local

services:
  # ===========================================================================
  # Database - PostgreSQL
  # ===========================================================================
  postgres:
    image: postgres:15-alpine
    container_name: inventory-postgres
    restart: unless-stopped
    networks:
      - inventory-network
    environment:
      POSTGRES_USER: ${DB_USER:-inventory}
      POSTGRES_PASSWORD: ${DB_PASSWORD:-inventory123}
      POSTGRES_DB: ${DB_NAME:-inventory_db}
      POSTGRES_INITDB_ARGS: "--encoding=UTF8 --locale=en_US.UTF-8"
      PGDATA: /var/lib/postgresql/data/pgdata
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - backup_data:/backups
    ports:
      - "${DB_PORT:-5432}:5432"
    healthcheck:
      test:
        [
          "CMD-SHELL",
          "pg_isready -U ${DB_USER:-inventory} -d ${DB_NAME:-inventory_db}",
        ]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # ===========================================================================
  # Cache & Session Store - Redis
  # ===========================================================================
  redis:
    image: redis:7-alpine
    container_name: inventory-redis
    restart: unless-stopped
    networks:
      - inventory-network
    command: redis-server --appendonly yes --requirepass ${REDIS_PASSWORD:-}
    volumes:
      - redis_data:/data
    ports:
      - "${REDIS_PORT:-6379}:6379"
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # ===========================================================================
  # API Server - Node.js Express
  # ===========================================================================
  api:
    build:
      context: ..
      dockerfile: Dockerfile
      target: api-production
      args:
        NODE_VERSION: "20"
    container_name: inventory-api
    restart: unless-stopped
    networks:
      - inventory-network
    environment:
      NODE_ENV: ${NODE_ENV:-production}
      PORT: ${API_PORT:-3001}
      DATABASE_URL: postgresql://${DB_USER:-inventory}:${DB_PASSWORD:-inventory123}@postgres:5432/${DB_NAME:-inventory_db}
      REDIS_URL: redis://${REDIS_PASSWORD:+:${REDIS_PASSWORD}@}redis:6379
      JWT_SECRET: ${JWT_SECRET}
      JWT_REFRESH_SECRET: ${JWT_REFRESH_SECRET}
      SESSION_SECRET: ${SESSION_SECRET}
      WEB_URL: ${WEB_URL:-https://admin.yourtechassist.us}
      PORTAL_URL: ${PORTAL_URL:-https://portal.yourtechassist.us}
      CORS_ORIGINS: ${CORS_ORIGINS}
      SMTP_HOST: ${SMTP_HOST}
      SMTP_PORT: ${SMTP_PORT}
      SMTP_USER: ${SMTP_USER}
      SMTP_PASS: ${SMTP_PASS}
      EMAIL_FROM_NAME: ${EMAIL_FROM_NAME}
      EMAIL_FROM_ADDRESS: ${EMAIL_FROM_ADDRESS}
      ANTHROPIC_API_KEY: ${ANTHROPIC_API_KEY}
      OPENAI_API_KEY: ${OPENAI_API_KEY}
      SENTRY_DSN: ${SENTRY_DSN}
      LOG_LEVEL: ${LOG_LEVEL:-info}
      ML_ANALYTICS_URL: ${ML_ANALYTICS_URL:-http://ml-analytics:8000}
    volumes:
      - uploads_data:/app/uploads
      - ../apps/api/prisma:/app/prisma
    ports:
      - "${API_PORT:-3001}:3001"
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "wget", "-q", "--spider", "http://localhost:3001/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "5"

  # ===========================================================================
  # ML Analytics Service - Python FastAPI
  # ===========================================================================
  ml-analytics:
    build:
      context: ../apps/ml-analytics
      dockerfile: Dockerfile
    container_name: inventory-ml-analytics
    restart: unless-stopped
    networks:
      - inventory-network
    environment:
      DATABASE_URL: postgresql://${DB_USER:-inventory}:${DB_PASSWORD:-inventory123}@postgres:5432/${DB_NAME:-inventory_db}
      PORT: 8000
      HOST: 0.0.0.0
      LOG_LEVEL: ${LOG_LEVEL:-info}
      MODEL_PATH: /app/models
    volumes:
      - ml_models:/app/models
    ports:
      - "${ML_PORT:-8000}:8000"
    depends_on:
      postgres:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "wget", "-q", "--spider", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # ===========================================================================
  # Web Dashboard & Portal - Nginx Static Server
  # ===========================================================================
  web:
    build:
      context: ..
      dockerfile: Dockerfile
      target: static-production
    container_name: inventory-web
    restart: unless-stopped
    networks:
      - inventory-network
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/inventory-docker.conf:/etc/nginx/nginx.conf:ro
      - ./ssl:/etc/nginx/ssl:ro
    depends_on:
      - api
    healthcheck:
      test: ["CMD", "wget", "-q", "--spider", "http://localhost/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # ===========================================================================
  # Database Backup Service (Optional)
  # ===========================================================================
  backup:
    image: postgres:15-alpine
    container_name: inventory-backup
    restart: "no"
    networks:
      - inventory-network
    environment:
      POSTGRES_USER: ${DB_USER:-inventory}
      POSTGRES_PASSWORD: ${DB_PASSWORD:-inventory123}
      POSTGRES_DB: ${DB_NAME:-inventory_db}
      BACKUP_DIR: /backups
      BACKUP_KEEP_DAYS: ${BACKUP_KEEP_DAYS:-7}
    volumes:
      - backup_data:/backups
      - ./scripts/backup-db.sh:/backup.sh:ro
    depends_on:
      - postgres
    command: /bin/sh -c "while true; do sleep 86400; done"
    profiles:
      - backup

# =============================================================================
# Usage Instructions:
# =============================================================================
#
# 1. Copy .env.production.example to .env and configure
# 2. Start all services:
#    docker-compose -f deploy/docker-compose.production.yml up -d
#
# 3. View logs:
#    docker-compose -f deploy/docker-compose.production.yml logs -f [service]
#
# 4. Stop all services:
#    docker-compose -f deploy/docker-compose.production.yml down
#
# 5. Backup database:
#    docker-compose -f deploy/docker-compose.production.yml --profile backup up backup
#
# 6. Scale API service:
#    docker-compose -f deploy/docker-compose.production.yml up -d --scale api=3
# =============================================================================
